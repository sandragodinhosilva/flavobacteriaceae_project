{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Sandra Godinho Silva \\\n",
    "Most updated version: 0.2 from 07/09/2020 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 5)\n",
    "pd.set_option('display.max_columns', 1000)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Make sure I'm working with the correct genomes:\n",
    "while read l; do cp  $l* /data/msb/silva/NEW/3_Annotation/Fasta_selected/ ; done < /data/msb/silva/NEW/assembly_ids.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Prokka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prokka: https://github.com/tseemann/prokka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1 Run script that formats .fasta files by shortening contig headers: contig_nammer.py** \\\n",
    "Utility: Fasta files downloaded from NCBI sometimes have long contig headers, making the files unsuitable as input to run Prokka. Running this script on the fasta files solves the problem."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Coded for running within EVE Linux cluster system.\n",
    "### To run script conting_namer.py in eve:\n",
    "module purge\n",
    "module load GCCcore/8.3.0\n",
    "module load Python/3.7.4\n",
    "python contig_namer.py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2 File division into subdirectories** \\\n",
    "Divide genomes into folders with 5 genomes before job submission to increase job speed on EVE cluster.\n",
    "Input: folder with the genomes in fasta format."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "folder_divider.sh\n",
    "\n",
    "To revert the process (move all files from subdirectories to current directory):\n",
    "find ./*/* -type f -print0 | xargs -0 -I % mv % .\n",
    "\n",
    "Move 50 folders to a subdirectory:\n",
    "ls | head -200 | xargs -I{} mv {} /data/msb/silva/NEW/3_Annotation/Fasta/SUB1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3 For loop submission on eve:** \\\n",
    "Input: folder containing all the folders created in the last step. Each folder contains 5 genomes."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Coded for running within EVE Linux cluster system.\n",
    "for i in *; do qsub -N $i /data/msb/silva/NEW/prokka_script_non_paral.sh  /data/msb/silva/NEW/3_Annotation/Missing_prokka/$i /data/msb/silva/NEW/3_Annotation/Missing_prokka_done/$i ; done\n",
    "\n",
    "$1: folder with bins \n",
    "$2: output folder\n",
    "\n",
    "Important notes: \n",
    "- submit paths to directories not to .fa files;\n",
    "- if the output folder already has content, this will be overwritten by Prokka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find /data/msb/silva/NEW/3_Annotation/Prokka -type f -name '*.gbk' -print0 | xargs -0 -I % cp % ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find . -name \\*.gbk -exec cp {} /data/msb/silva/Prokka_ano/prokka_out/Gbk/ \\;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Pfam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1 To annotate the genomes into Pfams, a local database is created.** \\\n",
    "Download lastest Pfam-A.hmm:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "wget ftp://ftp.ebi.ac.uk/pub/databases/Pfam/current_release/Pfam-A.hmm.gz\n",
    "gunzip Pfam-A.hmm.gz\n",
    "    \n",
    "Pfam 33.1 (May 2020, 18259 entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2 Run hmmsearch** \\\n",
    "To run hhmsearch is necessary to install Hmmer. Creating a conda environment is the easiest option:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "conda create --name pfam_env\n",
    "conda activate pfam_env\n",
    "conda install -c bioconda hmmer"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "hmmsearch --tblout \"$1\" -E 1e-5 \"$2\" \"$3\" \n",
    "\n",
    "Note: to change cuttof, replace 1e-5 with the desired value.\n",
    "\n",
    "Coded for running within EVE Linux cluster system:\n",
    "\n",
    "#1 is the output tblout filename (e.g: genomeA_tblout.txt)\n",
    "#2 is the database\n",
    "#3 is the input genome in .faa format \n",
    "\n",
    "for i in *.faa; do qsub -N ${i%.*} /data/msb/silva/NEW/hmmsearch_script.sh /data/msb/silva/NEW/3_Annotation/Pfam/${i%.*}_tblout.txt /data/msb/silva/Pfam_database/Pfam-A.hmm /data/msb/silva/NEW/3_Annotation/Faa/direc0/$i; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3 Convert tblout files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python /data/msb/silva/NEW/3_Annotation/tblout2.py ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 COG\n",
    "Adapted from https://github.com/aleimba/bac-genomics-scripts/tree/master/cdd2cog \\\n",
    "e value: 0.001 (1e-5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now cite the latest major release (tag: bovine_ecoli_mastitis) hosted on Zenodo:\n",
    "\n",
    "Leimbach A. 2016. bac-genomics-scripts: Bovine E. coli mastitis comparative genomics edition. Zenodo. http://dx.doi.org/10.5281/zenodo.215824."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1 Installation:**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "conda create --name cog_env\n",
    "conda activate cog_env\n",
    "All scripts are tested with Perl v5.22.1.\n",
    "\n",
    "# get script and all needed data\n",
    "wget https://raw.githubusercontent.com/aleimba/bac-genomics-scripts/master/cdd2cog/cdd2cog.pl\n",
    "## CDD\n",
    "wget ftp://ftp.ncbi.nlm.nih.gov/pub/mmdb/cdd/cddid.tbl.gz\n",
    "gunzip cddid.tbl.gz\n",
    "wget ftp://ftp.ncbi.nlm.nih.gov/pub/mmdb/cdd/little_endian/Cog_LE.tar.gz\n",
    "tar xvfz Cog_LE.tar.gz\n",
    "## COG\n",
    "wget ftp://ftp.ncbi.nlm.nih.gov/pub/COG/COG/fun.txt\n",
    "wget ftp://ftp.ncbi.nlm.nih.gov/pub/COG/COG/whog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2 In the folder with the Faa files from Prokka: rpsblast** "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Coded for running within EVE Linux cluster system:\n",
    "for i in *; do echo qsub /data/msb/silva/sub_scripts/cdd2cog_rpsblast.sh /data/msb/silva/Prokka_anno/prokka_out/Fna/$i /data/msb/silva/COG/Output_rpsblast/${i%.*}.out; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2 In the folder with the output files from rpsblast: Prokkacdd2cog**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Coded for running within EVE Linux cluster system.\n",
    "for i in *.out; do echo qsub /data/msb/silva/sub_scripts/cdd2cog.sh /data/msb/silva/COG/Output_rpsblast/$i /data/msb/silva/COG/Output_cogs/${i%.*}; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 CAZymes\n",
    "To annotate the genomes in terms of CAZymes, the following script was used: https://github.com/linnabrown/run_dbcan \\\n",
    "**4.1 In the folder with tha Faa files from Prokka: run_dbcan**\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Coded for running within EVE Linux cluster system.\n",
    "for i in *.faa; do echo qsub -N ${i%.*} /data/msb/silva/NEW/dbcan_sub.sh ${i%.*}_  /data/msb/silva/NEW/3_Annotation/Faa/direc0/$i /data/msb/silva/NEW/3_Annotation/Cazymes/; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 KEGG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the Kegg annotation, a script that converts Prokka annotation into KOs is used: https://github.com/SilentGene/Bio-py/tree/master/prokka2kegg \\\n",
    "For that purpose, KO entries (K numbers in KEGG annotation) are assigned *in batch mode* according to UniProtKB ID in `Prokka` *.gbk files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.1 Prepare the cross-reference database provided by UniProt**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Step1: Download and initialize the cross-reference database provided by UniProt\n",
    "wget ftp://ftp.uniprot.org/pub/databases/uniprot/current_release/knowledgebase/idmapping/idmapping.dat.gz\n",
    "gzip -dc idmapping.dat.gz | awk '{if($2==\"KO\") print $1,$3}' OFS=\"\\t\" | gzip > idmapping_KO.tab.gz\n",
    "\n",
    "You could choose to remove 'idmapping.dat.gz' now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.2 In the folder with tha Gbk files from Prokka: prokka2kegg.py** \\"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Step2: Retrieve K numbers according to the UniProtKB IDs of proteins\n",
    "$ python3 gbk2kegg_batch.py -i input_dir -d idmapping_KO.tab.gz -o output_dir"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Coded for running within EVE Linux cluster system: \n",
    "\n",
    "#1 is the gbk folder\n",
    "#2 is the output folder\n",
    "\n",
    "/data/msb/silva/prokka2kegg/prokka2kegg_batch.py -i \"$1\" -d /data/msb/silva/prokka2kegg/idmapping_KO.tab.gz -o  \"$2\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Create count tables and merge annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run **orf_annotation.py**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 antiSMASH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.1 Format .gbk file headers to use them as input in antiSMASH: gbk_file_formater.py** \\\n",
    "Utility: Output files from Prokka annotation can have some incompatibilities with the required antiSMASH input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.2 Create output directories:**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i in *; do mkdir /data/msb/silva/antismash_results2/${i%.*}; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.3 Run antismash** \\\n",
    "options chosen: "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Coded for running within EVE Linux cluster system: \n",
    "\n",
    "for i in *.gbk; do echo -N $i /data/msb/silva/sub_scripts/submission_antismash.sh /data/msb/silva/Gbk_antismash2/$i /data/msb/silva/antismash_results2/${i%.*}/ ; done;"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Script adds a prefix (subdirectory name) to all .gbk files inside the subdirectories. gbk_renamer.sh\n",
    "Utility: Usefull to format antiSMASH v5.0 results for other analysis so they are trackable.\n",
    "\n",
    "bash /data/msb/silva/NEW/3_Annotation/gbk_renamer.sh\n",
    "\n",
    "Script to summarize results from antiSMASH v5.0 into a csv file per genome and summary table with BGC type counts per genome: antismash_html_tocsv.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 BIG-SCAPE"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Coded for running within EVE Linux cluster system: \n",
    "\n",
    "qsub -N bigscape_september bigscape_submission2.sh /data/msb/silva/NEW/3_Annotation/antismash_security/ /data/msb/silva/NEW/3_Annotation/bigscape/"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "If the job is interrupted by a error, try: fasta_cleanner.py in the bigscape/cache/fasta directory.\n",
    "This script cleans .fasta files that have unwanted lines starting with '-' which makes the job to stop.\n",
    "Utility: While running BiG-SCAPE, the workflow may stop due to lines starting with '-' in some .fasta files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prokka** \\\n",
    "Seemann, T. “Prokka: Rapid Prokaryotic Genome Annotation.” Bioinformatics 30, no. 14\n",
    "(July 15, 2014): 2068–69. https://doi.org/10.1093/bioinformatics/btu153 .\n",
    "\n",
    "**antiSMASH** \\\n",
    "antiSMASH 5.0: updates to the secondary metabolite genome mining pipeline\n",
    "Kai Blin, Simon Shaw, Katharina Steinke, Rasmus Villebro, Nadine Ziemert, Sang Yup Lee, Marnix H Medema, & Tilmann Weber. Nucleic Acids Research (2019) https://doi.org/10.1093/nar/gkz310 ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
