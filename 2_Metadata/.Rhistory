install.packages(c("DataExplorer", "tidyverse"))
library("DataExplorer")
library(ggplot2)
setwd("C:/Users/borimcor/Dropbox/professional_career/17_20_doutorado/thesis/writing/01_tmdb_files/tmdb_paper/3rd_submission_review_accepted/figures/figure_02_descriptive/")
df <- read.delim("tmdb_oct2019.tsv", stringsAsFactors = F)
####### Plot A1 - Sample Location (Country)
na.omit(group_category(df, "sample_location", 0.17))
location_groupped <- group_category(df, "sample_location", 0.17, update = TRUE, category_name="OTHER")
p <- plot_bar(na.omit(location_groupped$sample_location),title = "",
# p <- plot_bar(location_groupped$sample_location,title = "",
ggtheme = theme_minimal())
ggsave("source.eps", device = "eps", units="in", width=5.9, height=6.3, dpi=600)
###### Plot A2 - Source Database + Sequencing Platform
# Plots not combined
plot_bar(df$source_database)
plot_bar(df$seq_platform)
library(tidyverse)
df_platform <- group_category(df, "seq_platform", 0.015, update=TRUE, category_name="OTHER")
df_platform$source_database <- fct_infreq(df_platform$source_database)
# Trying some color schemes
cbPalette <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
library(RColorBrewer)
display.brewer.all(colorblindFriendly = TRUE)
display.brewer.pal(n = 8, name = 'cbPalette')
# Plot "Source Database + Sequencing Platform"
p <- ggplot(df_platform, aes(x = source_database, fill=seq_platform)) +
#scale_fill_manual(values=cbbPalette) +
scale_fill_brewer(palette = "Set2", na.value="grey50") +
#scale_y_continuous(limits=c(0,1), breaks=c(0,0.2,0.4,0.6,0.8,1), labels=c("0","20","40","60","80","100")) +
geom_bar(stat="count", position ="stack",width = 0.7) +
theme_minimal()
#facet_wrap(~source_database, nrow = 1)# +
#coord_flip()
p + ylab(label = "") +
xlab(label = "") +
labs(fill = "") +
theme(text = element_text(size=20)) +
theme(legend.position="bottom")
ggsave("source.eps", device = "eps", units="in", width=5.9, height=7.3, dpi=600)
install.packages(c("ggraph", "tidytext", "widyr"))
## THIS SCRIPT PLOTS THE WORD NETWORK
library(tidyr)
library(dplyr)
library(tidytext)
library(ggplot2)
library(igraph)
library(ggraph)
setwd("~/tmdb_paper/figures/biomes_graph")
# This file was prepared with the dataset "tmdb_may2019", using the "envo" terms columns
custom_envo <- read.delim("tmdb_biomes.tsv", colClasses = 'character')
#-----------------------
# BIOME
custom_biome <- na.omit(custom_envo$custom_biome)
# MATERIAL
custom_material <- na.omit(custom_envo$custom_material)
# PLOT_FUNCTION
plot_graph_singlecol <- function(data_input, edge_color, title){
biomes_df <- tibble(line = 1:length(data_input), text = data_input)
tokens <- biomes_df %>% unnest_tokens(word, text, token = stringr::str_split, pattern = ",", to_lower = FALSE)
tokens_freq <- count(tokens, word)
library(widyr)
tokens_pairs <- tokens %>%
pairwise_count(word, line, sort = TRUE, upper = FALSE)
set.seed(999)
tokens_pairs %>%
#filter(n >= 200) %>%
graph_from_data_frame(vertices = tokens %>% count(word)) %>%
ggraph(layout = "nicely") +
geom_edge_link(aes(edge_alpha = n, edge_width = n), edge_colour = edge_color) +
geom_node_point(aes(size = tokens_freq$n), colour="grey45") + scale_size(range = c(1,10)) +
geom_node_text(aes(label = name), repel = TRUE,
point.padding = unit(0.4, "lines"),
size = 3) +
labs(size="Number of\noccurences", edge_alpha="Pairwise\ncount", edge_width="Pairwise\ncount") +
theme_light() +
theme(axis.title.x=element_blank(),
axis.title.y=element_blank(),
axis.ticks=element_blank(),
axis.text=element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank()#,
#legend.position="bottom"
)# +
#ggtitle(title)
#theme_void()
}
# SAVE PLOT IN VARIABLES
a <- plot_graph_singlecol(custom_biome, "darkgreen")
b <- plot_graph_singlecol(custom_material, "lightskyblue3")
# Load libraries for dual plot
library(gridExtra)
library(grid)
png("graphs_hires.png", width = 200, height = 240, units = 'mm', res = 300)
plot <- print(grid.arrange(a, b, ncol=1, nrow=2),
grid.text(c("custom_biome","custom_material"), x = c(0.15,0.15), y = c(0.95,0.45),
gp = gpar(fontsize=16, fontfamily="Helvetica")
)
)
dev.off()
## THIS SCRIPT PLOTS THE WORD NETWORK
library(tidyr)
library(dplyr)
library(tidytext)
library(ggplot2)
library(igraph)
library(ggraph)
#setwd("~/tmdb_paper/figures/biomes_graph")
# This file was prepared with the dataset "tmdb_may2019", using the "envo" terms columns
custom_envo <- read.delim("tmdb_biomes.tsv", colClasses = 'character')
#-----------------------
# This file was prepared with the dataset "tmdb_may2019", using the "envo" terms columns
custom_envo <- read.delim("tmdb_may2019.tsv", colClasses = 'character')
# This file was prepared with the dataset "tmdb_may2019", using the "envo" terms columns
custom_envo <- read.delim("tmdb_oct2019.tsv", colClasses = 'character')
View(custom_envo)
library(DBI)  #A database interface for communication between R and relational database management systems
library(RSQLite)  #Embeds the 'SQLite' database engine in R and provides an interface compliant with the 'DBI' package
library(SRAdb)    #A compilation of metadata from NCBI SRA and tools
#SRAdb allows accessing data in SRA by finding it first.
#Also determines availability of sequence files and to download files of interest.
#experiment accessions (SRX, ERX or DRX) and run accessions (SRR, ERR or DRR)
#SRA is a continuously growing repository. So the SRAdb SQLite file is updated regularly.
#Then, the 1st step is to get the SRAdb SQLite  file from the online location.
#download and uncompress steps are done with a single command, getSRAdbFile.
# Downloading SRAdb file if it does not exist
if (!file.exists("SRAmetadb.sqlite")) sra_dbname <- getSRAdbFile() else sra_dbname <- "SRAmetadb.sqlite"
#Then, create a connection for later queries. The standard DBI functionality as imple-
#mented in RSQLite function dbConnect makes the connection to the database.
sra_con <- dbConnect(dbDriver("SQLite"), sra_dbname)
# Import 'srr_wgs_ids.txt' as a vector
srr_list <- read.csv('srr_ids.txt', header = FALSE)
srr_list <- as.vector(srr_list[[1]])
# Map srr_list ids to the respective "run_accession" in "sra" table
#sprintf returns a character vector containing a combination of text and variable values
for (i in 1:length(srr_list)){
sra_row <- dbGetQuery(sra_con, sprintf("select * from sra where run_accession = '%s' limit 1", srr_list[i]))
# Combine rows
if (i == 1){sra_df <- sra_row}
else {sra_df <- rbind.data.frame(sra_df, sra_row)}
}
# Removing line breaks in free text columns
# I have identified that some columns with free text inside have unexpected break lines and that was causing problems in the final file
sra_df$read_spec <- gsub("\r?\n|\r", "", sra_df$read_spec)
sra_df$sample_attribute <- gsub("\r?\n|\r", "", sra_df$sample_attribute)
sra_df$description <- gsub("\r?\n|\r", "", sra_df$description)
# Removing columns where all the values are NA
filtered_df <- sra_df[,colSums(is.na(sra_df))<nrow(sra_df)]
filtered_df <- subset(filtered_df, library_strategy == "WGS" & library_source == "GENOMIC")
# Write to a file
write.table(filtered_df, "flavo_reads_dataset.txt", sep = "\t", eol = "\n", row.names = F, col.names = T)
setwd("/home/gomes/silva/Task_Metadata/sandra/01_edirect_scripts/ncbi_fungal_assembly_id_to_srr_id/02_srr_to_sradb"")
library(DBI)  #A database interface for communication between R and relational database management systems
library(RSQLite)  #Embeds the 'SQLite' database engine in R and provides an interface compliant with the 'DBI' package
library(SRAdb)    #A compilation of metadata from NCBI SRA and tools
#SRAdb allows accessing data in SRA by finding it first.
#Also determines availability of sequence files and to download files of interest.
#experiment accessions (SRX, ERX or DRX) and run accessions (SRR, ERR or DRR)
#SRA is a continuously growing repository. So the SRAdb SQLite file is updated regularly.
#Then, the 1st step is     to get the SRAdb SQLite  file from the online location.
#download and uncompress steps are done with a single command, getSRAdbFile.
# Downloading SRAdb file if it does not exist
if (!file.exists("SRAmetadb.sqlite")) sra_dbname <- getSRAdbFile() else sra_dbname <- "SRAmetadb.sqlite"
#Then, create a connection for later queries. The standard DBI functionality as imple-
#mented in RSQLite function dbConnect makes the connection to the database.
sra_con <- dbConnect(dbDriver("SQLite"), sra_dbname)
# Import 'srr_wgs_ids.txt' as a vector
srr_list <- read.csv('srr_ids.txt', header = FALSE)
srr_list <- as.vector(srr_list[[1]])
# Map srr_list ids to the respective "run_accession" in "sra" table
#sprintf returns a character vector containing a combination of text and variable values
for (i in 1:length(srr_list)){
sra_row <- dbGetQuery(sra_con, sprintf("select * from sra where run_accession = '%s' limit 1", srr_list[i]))
# Combine rows
if (i == 1){sra_df <- sra_row}
else {sra_df <- rbind.data.frame(sra_df, sra_row)}
}
# Removing line breaks in free text columns
# I have identified that some columns with free text inside have unexpected break lines and that was causing problems in the final file
sra_df$read_spec <- gsub("\r?\n|\r", "", sra_df$read_spec)
sra_df$sample_attribute <- gsub("\r?\n|\r", "", sra_df$sample_attribute)
sra_df$description <- gsub("\r?\n|\r", "", sra_df$description)
# Removing columns where all the values are NA
filtered_df <- sra_df[,colSums(is.na(sra_df))<nrow(sra_df)]
filtered_df <- subset(filtered_df, library_strategy == "WGS" & library_source == "GENOMIC")
# Write to a file
write.table(filtered_df, "flavo_reads_dataset.txt", sep = "\t", eol = "\n", row.names = F, col.names = T)
setwd("/home/gomes/silva/Task_Metadata/sandra/01_edirect_scripts/ncbi_fungal_assembly_id_to_srr_id/02_srr_to_sradb")
getwd()
library(DBI)  #A database interface for communication between R and relational database management systems
library(RSQLite)  #Embeds the 'SQLite' database engine in R and provides an interface compliant with the 'DBI' package
library(SRAdb)    #A compilation of metadata from NCBI SRA and tools
#SRAdb allows accessing data in SRA by finding it first.
#Also determines availability of sequence files and to download files of interest.
#experiment accessions (SRX, ERX or DRX) and run accessions (SRR, ERR or DRR)
#SRA is a continuously growing repository. So the SRAdb SQLite file is updated regularly.
#Then, the 1st step is     to get the SRAdb SQLite  file from the online location.
#download and uncompress steps are done with a single command, getSRAdbFile.
# Downloading SRAdb file if it does not exist
if (!file.exists("SRAmetadb.sqlite")) sra_dbname <- getSRAdbFile() else sra_dbname <- "SRAmetadb.sqlite"
#Then, create a connection for later queries. The standard DBI functionality as imple-
#mented in RSQLite function dbConnect makes the connection to the database.
sra_con <- dbConnect(dbDriver("SQLite"), sra_dbname)
# Import 'srr_wgs_ids.txt' as a vector
srr_list <- read.csv('srr_ids.txt', header = FALSE)
srr_list <- as.vector(srr_list[[1]])
# Map srr_list ids to the respective "run_accession" in "sra" table
#sprintf returns a character vector containing a combination of text and variable values
for (i in 1:length(srr_list)){
sra_row <- dbGetQuery(sra_con, sprintf("select * from sra where run_accession = '%s' limit 1", srr_list[i]))
# Combine rows
if (i == 1){sra_df <- sra_row}
else {sra_df <- rbind.data.frame(sra_df, sra_row)}
}
# Removing line breaks in free text columns
# I have identified that some columns with free text inside have unexpected break lines and that was causing problems in the final file
sra_df$read_spec <- gsub("\r?\n|\r", "", sra_df$read_spec)
sra_df$sample_attribute <- gsub("\r?\n|\r", "", sra_df$sample_attribute)
sra_df$description <- gsub("\r?\n|\r", "", sra_df$description)
# Removing columns where all the values are NA
filtered_df <- sra_df[,colSums(is.na(sra_df))<nrow(sra_df)]
filtered_df <- subset(filtered_df, library_strategy == "WGS" & library_source == "GENOMIC")
# Write to a file
write.table(filtered_df, "flavo_reads_dataset.txt", sep = "\t", eol = "\n", row.names = F, col.names = T)
setwd("/home/gomes/silva/Task_Metadata/sandra/01_edirect_scripts/ncbi_fungal_assembly_id_to_srr_id/02_srr_to_sradb")
library(DBI)  #A database interface for communication between R and relational database management systems
library(RSQLite)  #Embeds the 'SQLite' database engine in R and provides an interface compliant with the 'DBI' package
library(SRAdb)    #A compilation of metadata from NCBI SRA and tools
#SRAdb allows accessing data in SRA by finding it first.
#Also determines availability of sequence files and to download files of interest.
#experiment accessions (SRX, ERX or DRX) and run accessions (SRR, ERR or DRR)
#SRA is a continuously growing repository. So the SRAdb SQLite file is updated regularly.
#Then, the 1st step is     to get the SRAdb SQLite  file from the online location.
#download and uncompress steps are done with a single command, getSRAdbFile.
# Downloading SRAdb file if it does not exist
if (!file.exists("SRAmetadb.sqlite")) sra_dbname <- getSRAdbFile() else sra_dbname <- "SRAmetadb.sqlite"
#Then, create a connection for later queries. The standard DBI functionality as imple-
#mented in RSQLite function dbConnect makes the connection to the database.
sra_con <- dbConnect(dbDriver("SQLite"), sra_dbname)
setwd("/home/gomes/silva2/2_Metadata")
library(DBI)  #A database interface for communication between R and relational database management systems
library(RSQLite)  #Embeds the 'SQLite' database engine in R and provides an interface compliant with the 'DBI' package
library(SRAdb)
if (!file.exists("SRAmetadb.sqlite")) sra_dbname <- getSRAdbFile() else sra_dbname <- "SRAmetadb.sqlite"
setwd("/home/gomes/silva2/2_Metadata")
library(DBI)  #A database interface for communication between R and relational database management systems
library(RSQLite)  #Embeds the 'SQLite' database engine in R and provides an interface compliant with the 'DBI' package
library(SRAdb)    #A compilation of metadata from NCBI SRA and tools
#SRAdb allows accessing data in SRA by finding it first.
#Also determines availability of sequence files and to download files of interest.
#experiment accessions (SRX, ERX or DRX) and run accessions (SRR, ERR or DRR)
#SRA is a continuously growing repository. So the SRAdb SQLite file is updated regularly.
#Then, the 1st step is to get the SRAdb SQLite  file from the online location.
#download and uncompress steps are done with a single command, getSRAdbFile.
# Downloading SRAdb file if it does not exist
if (!file.exists("SRAmetadb.sqlite")) sra_dbname <- getSRAdbFile() else sra_dbname <- "SRAmetadb.sqlite"
#Then, create a connection for later queries. The standard DBI functionality as imple-
#mented in RSQLite function dbConnect makes the connection to the database.
sra_con <- dbConnect(dbDriver("SQLite"), sra_dbname)
# Import 'srr_wgs_ids.txt' as a vector
srr_list <- read.csv('srr_ids.txt', header = FALSE)
srr_list <- as.vector(srr_list[[1]])
# Map srr_list ids to the respective "run_accession" in "sra" table
#sprintf returns a character vector containing a combination of text and variable values
for (i in 1:length(srr_list)){
sra_row <- dbGetQuery(sra_con, sprintf("select * from sra where run_accession = '%s' limit 1", srr_list[i]))
# Combine rows
if (i == 1){sra_df <- sra_row}
else {sra_df <- rbind.data.frame(sra_df, sra_row)}
}
# Removing line breaks in free text columns
# I have identified that some columns with free text inside have unexpected break lines and that was causing problems in the final file
sra_df$read_spec <- gsub("\r?\n|\r", "", sra_df$read_spec)
sra_df$sample_attribute <- gsub("\r?\n|\r", "", sra_df$sample_attribute)
sra_df$description <- gsub("\r?\n|\r", "", sra_df$description)
# Removing columns where all the values are NA
filtered_df <- sra_df[,colSums(is.na(sra_df))<nrow(sra_df)]
filtered_df <- subset(filtered_df, library_strategy == "WGS" & library_source == "GENOMIC")
# Write to a file
write.table(filtered_df, "flavo_reads_dataset.txt", sep = "\t", eol = "\n", row.names = F, col.names = T)
setwd("/home/gomes/silva2/2_Metadata")
library(DBI)  #A database interface for communication between R and relational database management systems
library(RSQLite)  #Embeds the 'SQLite' database engine in R and provides an interface compliant with the 'DBI' package
library(SRAdb)    #A compilation of metadata from NCBI SRA and tools
#SRAdb allows accessing data in SRA by finding it first.
#Also determines availability of sequence files and to download files of interest.
#experiment accessions (SRX, ERX or DRX) and run accessions (SRR, ERR or DRR)
#SRA is a continuously growing repository. So the SRAdb SQLite file is updated regularly.
#Then, the 1st step is to get the SRAdb SQLite  file from the online location.
#download and uncompress steps are done with a single command, getSRAdbFile.
# Downloading SRAdb file if it does not exist
if (!file.exists("SRAmetadb.sqlite")) sra_dbname <- getSRAdbFile() else sra_dbname <- "SRAmetadb.sqlite"
#Then, create a connection for later queries. The standard DBI functionality as imple-
#mented in RSQLite function dbConnect makes the connection to the database.
sra_con <- dbConnect(dbDriver("SQLite"), sra_dbname)
# Import 'srr_wgs_ids.txt' as a vector
srr_list <- read.csv('srr_ids.txt', header = FALSE)
srr_list <- as.vector(srr_list[[1]])
# Map srr_list ids to the respective "run_accession" in "sra" table
#sprintf returns a character vector containing a combination of text and variable values
for (i in 1:length(srr_list)){
sra_row <- dbGetQuery(sra_con, sprintf("select * from sra where run_accession = '%s' limit 1", srr_list[i]))
# Combine rows
if (i == 1){sra_df <- sra_row}
else {sra_df <- rbind.data.frame(sra_df, sra_row)}
}
# Removing line breaks in free text columns
# I have identified that some columns with free text inside have unexpected break lines and that was causing problems in the final file
sra_df$read_spec <- gsub("\r?\n|\r", "", sra_df$read_spec)
sra_df$sample_attribute <- gsub("\r?\n|\r", "", sra_df$sample_attribute)
sra_df$description <- gsub("\r?\n|\r", "", sra_df$description)
# Removing columns where all the values are NA
filtered_df <- sra_df[,colSums(is.na(sra_df))<nrow(sra_df)]
filtered_df <- subset(filtered_df, library_strategy == "WGS" & library_source == "GENOMIC")
# Write to a file
write.table(filtered_df, "reads_dataset.txt", sep = "\t", eol = "\n", row.names = F, col.names = T)
# Write to a file
write.table(filtered_df, "reads_dataset.txt", sep = "\t", eol = "\n", row.names = F, col.names = T)
setwd("/home/gomes/silva2/2_Metadata")
library(DBI)  #A database interface for communication between R and relational database management systems
library(RSQLite)  #Embeds the 'SQLite' database engine in R and provides an interface compliant with the 'DBI' package
library(SRAdb)    #A compilation of metadata from NCBI SRA and tools
#SRAdb allows accessing data in SRA by finding it first.
#Also determines availability of sequence files and to download files of interest.
#experiment accessions (SRX, ERX or DRX) and run accessions (SRR, ERR or DRR)
#SRA is a continuously growing repository. So the SRAdb SQLite file is updated regularly.
#Then, the 1st step is to get the SRAdb SQLite  file from the online location.
#download and uncompress steps are done with a single command, getSRAdbFile.
# Downloading SRAdb file if it does not exist
if (!file.exists("SRAmetadb.sqlite")) sra_dbname <- getSRAdbFile() else sra_dbname <- "SRAmetadb.sqlite"
#Then, create a connection for later queries. The standard DBI functionality as imple-
#mented in RSQLite function dbConnect makes the connection to the database.
sra_con <- dbConnect(dbDriver("SQLite"), sra_dbname)
# Import 'srr_wgs_ids.txt' as a vector
srr_list <- read.csv('srr_ids.txt', header = FALSE)
srr_list <- as.vector(srr_list[[1]])
# Map srr_list ids to the respective "run_accession" in "sra" table
#sprintf returns a character vector containing a combination of text and variable values
for (i in 1:length(srr_list)){
sra_row <- dbGetQuery(sra_con, sprintf("select * from sra where run_accession = '%s' limit 1", srr_list[i]))
# Combine rows
if (i == 1){sra_df <- sra_row}
else {sra_df <- rbind.data.frame(sra_df, sra_row)}
}
# Removing line breaks in free text columns
# I have identified that some columns with free text inside have unexpected break lines and that was causing problems in the final file
sra_df$read_spec <- gsub("\r?\n|\r", "", sra_df$read_spec)
sra_df$sample_attribute <- gsub("\r?\n|\r", "", sra_df$sample_attribute)
sra_df$description <- gsub("\r?\n|\r", "", sra_df$description)
# Removing columns where all the values are NA
#filtered_df <- sra_df[,colSums(is.na(sra_df))<nrow(sra_df)]
#filtered_df <- subset(filtered_df, library_strategy == "WGS" & library_source == "GENOMIC")
# Write to a file
write.table(filtered_df, "reads_dataset.txt", sep = "\t", eol = "\n", row.names = F, col.names = T)
setwd("/home/gomes/silva2/2_Metadata")
library(DBI)  #A database interface for communication between R and relational database management systems
library(RSQLite)  #Embeds the 'SQLite' database engine in R and provides an interface compliant with the 'DBI' package
library(SRAdb)    #A compilation of metadata from NCBI SRA and tools
#SRAdb allows accessing data in SRA by finding it first.
#Also determines availability of sequence files and to download files of interest.
#experiment accessions (SRX, ERX or DRX) and run accessions (SRR, ERR or DRR)
#SRA is a continuously growing repository. So the SRAdb SQLite file is updated regularly.
#Then, the 1st step is to get the SRAdb SQLite  file from the online location.
#download and uncompress steps are done with a single command, getSRAdbFile.
# Downloading SRAdb file if it does not exist
if (!file.exists("SRAmetadb.sqlite")) sra_dbname <- getSRAdbFile() else sra_dbname <- "SRAmetadb.sqlite"
#Then, create a connection for later queries. The standard DBI functionality as imple-
#mented in RSQLite function dbConnect makes the connection to the database.
sra_con <- dbConnect(dbDriver("SQLite"), sra_dbname)
# Import 'srr_wgs_ids.txt' as a vector
srr_list <- read.csv('srr_ids.txt', header = FALSE)
srr_list <- as.vector(srr_list[[1]])
# Map srr_list ids to the respective "run_accession" in "sra" table
#sprintf returns a character vector containing a combination of text and variable values
for (i in 1:length(srr_list)){
sra_row <- dbGetQuery(sra_con, sprintf("select * from sra where run_accession = '%s' limit 1", srr_list[i]))
# Combine rows
if (i == 1){sra_df <- sra_row}
else {sra_df <- rbind.data.frame(sra_df, sra_row)}
}
# Removing line breaks in free text columns
# I have identified that some columns with free text inside have unexpected break lines and that was causing problems in the final file
sra_df$read_spec <- gsub("\r?\n|\r", "", sra_df$read_spec)
sra_df$sample_attribute <- gsub("\r?\n|\r", "", sra_df$sample_attribute)
sra_df$description <- gsub("\r?\n|\r", "", sra_df$description)
# Removing columns where all the values are NA
#filtered_df <- sra_df[,colSums(is.na(sra_df))<nrow(sra_df)]
#filtered_df <- subset(filtered_df, library_strategy == "WGS" & library_source == "GENOMIC")
# Write to a file
write.table(filtered_df, "reads_dataset.txt", sep = "\t", eol = "\n", row.names = F, col.names = T)
setwd("/home/gomes/silva2/2_Metadata")
library(DBI)  #A database interface for communication between R and relational database management systems
library(RSQLite)  #Embeds the 'SQLite' database engine in R and provides an interface compliant with the 'DBI' package
library(SRAdb)    #A compilation of metadata from NCBI SRA and tools
#SRAdb allows accessing data in SRA by finding it first.
#Also determines availability of sequence files and to download files of interest.
#experiment accessions (SRX, ERX or DRX) and run accessions (SRR, ERR or DRR)
#SRA is a continuously growing repository. So the SRAdb SQLite file is updated regularly.
#Then, the 1st step is to get the SRAdb SQLite  file from the online location.
#download and uncompress steps are done with a single command, getSRAdbFile.
# Downloading SRAdb file if it does not exist
if (!file.exists("SRAmetadb.sqlite")) sra_dbname <- getSRAdbFile() else sra_dbname <- "SRAmetadb.sqlite"
#Then, create a connection for later queries. The standard DBI functionality as imple-
#mented in RSQLite function dbConnect makes the connection to the database.
sra_con <- dbConnect(dbDriver("SQLite"), sra_dbname)
# Import 'srr_wgs_ids.txt' as a vector
srr_list <- read.csv('srr_ids.txt', header = FALSE)
srr_list <- as.vector(srr_list[[1]])
# Map srr_list ids to the respective "run_accession" in "sra" table
#sprintf returns a character vector containing a combination of text and variable values
for (i in 1:length(srr_list)){
sra_row <- dbGetQuery(sra_con, sprintf("select * from sra where run_accession = '%s' limit 1", srr_list[i]))
# Combine rows
if (i == 1){sra_df <- sra_row}
else {sra_df <- rbind.data.frame(sra_df, sra_row)}
}
# Removing line breaks in free text columns
# I have identified that some columns with free text inside have unexpected break lines and that was causing problems in the final file
sra_df$read_spec <- gsub("\r?\n|\r", "", sra_df$read_spec)
sra_df$sample_attribute <- gsub("\r?\n|\r", "", sra_df$sample_attribute)
sra_df$description <- gsub("\r?\n|\r", "", sra_df$description)
# Removing columns where all the values are NA
#filtered_df <- sra_df[,colSums(is.na(sra_df))<nrow(sra_df)]
#filtered_df <- subset(filtered_df, library_strategy == "WGS" & library_source == "GENOMIC")
# Write to a file
write.table(filtered_df, "reads_dataset.txt", sep = "\t", eol = "\n", row.names = F, col.names = T)
setwd("/home/gomes/silva2/2_Metadata")
library(DBI)  #A database interface for communication between R and relational database management systems
library(RSQLite)  #Embeds the 'SQLite' database engine in R and provides an interface compliant with the 'DBI' package
library(SRAdb)    #A compilation of metadata from NCBI SRA and tools
#SRAdb allows accessing data in SRA by finding it first.
#Also determines availability of sequence files and to download files of interest.
#experiment accessions (SRX, ERX or DRX) and run accessions (SRR, ERR or DRR)
#SRA is a continuously growing repository. So the SRAdb SQLite file is updated regularly.
#Then, the 1st step is to get the SRAdb SQLite  file from the online location.
#download and uncompress steps are done with a single command, getSRAdbFile.
# Downloading SRAdb file if it does not exist
if (!file.exists("SRAmetadb.sqlite")) sra_dbname <- getSRAdbFile() else sra_dbname <- "SRAmetadb.sqlite"
#Then, create a connection for later queries. The standard DBI functionality as imple-
#mented in RSQLite function dbConnect makes the connection to the database.
sra_con <- dbConnect(dbDriver("SQLite"), sra_dbname)
# Import 'srr_wgs_ids.txt' as a vector
srr_list <- read.csv('srr_ids.txt', header = FALSE)
srr_list <- as.vector(srr_list[[1]])
# Map srr_list ids to the respective "run_accession" in "sra" table
#sprintf returns a character vector containing a combination of text and variable values
for (i in 1:length(srr_list)){
sra_row <- dbGetQuery(sra_con, sprintf("select * from sra where run_accession = '%s' limit 1", srr_list[i]))
# Combine rows
if (i == 1){sra_df <- sra_row}
else {sra_df <- rbind.data.frame(sra_df, sra_row)}
}
# Removing line breaks in free text columns
# I have identified that some columns with free text inside have unexpected break lines and that was causing problems in the final file
sra_df$read_spec <- gsub("\r?\n|\r", "", sra_df$read_spec)
sra_df$sample_attribute <- gsub("\r?\n|\r", "", sra_df$sample_attribute)
sra_df$description <- gsub("\r?\n|\r", "", sra_df$description)
# Removing columns where all the values are NA
filtered_df <- sra_df[,colSums(is.na(sra_df))<nrow(sra_df)]
#filtered_df <- subset(filtered_df, library_strategy == "WGS" & library_source == "GENOMIC")
# Write to a file
write.table(filtered_df, "reads_dataset.txt", sep = "\t", eol = "\n", row.names = F, col.names = T)
